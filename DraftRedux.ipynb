{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "from tqdm import trange\n",
    "import tensorflow as tf\n",
    "\n",
    "from utils import *\n",
    "from ops import *\n",
    "from statistic import Statistic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set the parameters of the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hyperparams = {# network\n",
    "    \"model\" : \"pixel_cnn\", # name of model [pixel_rnn, pixel_cnn]\n",
    "    \"batch_size\" : 100, # size of a batch\n",
    "    \"hidden_dims\" : 16, # dimesion of hidden states of LSTM or Conv layers\n",
    "    \"recurrent_length\" : 7, # the length of LSTM or Conv layers\n",
    "    \"out_hidden_dims\" : 32, # dimesion of hidden states of output Conv layers\n",
    "    \"out_recurrent_length\" : 2, # the length of output Conv layers\n",
    "    \"use_residual\" : False, # whether to use residual connections or not\n",
    "    \"use_dynamic_rnn\" : False, # whether to use dynamic_rnn or not\n",
    "\n",
    "    # training\n",
    "    \"max_epoch\" : 100000, # # of step in an epoch\n",
    "    \"test_step\" : 100, # # of step to test a model\n",
    "    \"save_step\" : 1000, # # of step to save a model\n",
    "    \"learning_rate\" : 1e-3, # learning rate\n",
    "    \"grad_clip\" : 1, # value of gradient to be used for clipping\n",
    "    \"use_gpu\" : True, # whether to use gpu for training\n",
    "\n",
    "    # data\n",
    "    \"data\" : \"mnist\", # name of dataset \n",
    "    \"data_dir\" : \"MNIST-data\", # name of data directory\n",
    "    \"sample_dir\" : \"samples\", # name of sample directory\n",
    "\n",
    "    # Debug\n",
    "    \"is_train\" : True, # training or testing\n",
    "    \"display\" : False, # whether to display the training results or not\n",
    "    \"random_seed\" :  123 # random seed for python\n",
    "}\n",
    "p = dotdict(hyperparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if \"random_seed\" in p:\n",
    "    tf.set_random_seed(p.random_seed)\n",
    "    np.random.seed(p.random_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST-data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST-data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST-data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST-data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# TODO add hyperparams to model saving\n",
    "model_dir = setup_model_saving(p.model, p.data, hyperparams)\n",
    "DATA_DIR = p.data_dir\n",
    "SAMPLE_DIR = os.path.join(model_dir, p.sample_dir)\n",
    "\n",
    "check_and_create_dir(DATA_DIR)\n",
    "check_and_create_dir(SAMPLE_DIR)\n",
    "\n",
    "# prepare dataset\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(DATA_DIR, one_hot=True)\n",
    "\n",
    "next_train_batch = lambda x: mnist.train.next_batch(x)[0]\n",
    "next_test_batch = lambda x: mnist.test.next_batch(x)[0]\n",
    "\n",
    "height, width, channel = 28, 28, 1\n",
    "\n",
    "train_step_per_epoch = mnist.train.num_examples / p.batch_size\n",
    "test_step_per_epoch = mnist.test.num_examples / p.batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building CONV0\n",
      "Building CONV1\n",
      "Building CONV2\n",
      "Building CONV3\n",
      "Building CONV4\n",
      "Building CONV5\n",
      "Building CONV6\n",
      "Building CONV_OUT0\n",
      "Building CONV_OUT1\n"
     ]
    }
   ],
   "source": [
    "def pixelRNN(height, width, channel, params):\n",
    "    \"\"\"\n",
    "    Args\n",
    "    height, width, channel - the dimensions of the input\n",
    "    params -- the hyperparameters of the network\n",
    "    \"\"\"\n",
    "    input_shape = [None, height, width, channel] if params.use_gpu else [None, channel, height, width]\n",
    "    inputs = tf.placeholder(tf.float32, input_shape)\n",
    "    \n",
    "    # TODO remove scoping\n",
    "    # input of main reccurent layers\n",
    "    scope = \"conv_inputs\"\n",
    "    conv_inputs = conv2d(inputs, params.hidden_dims, [7, 7], \"A\", scope=scope)\n",
    "    \n",
    "    # main reccurent layers\n",
    "    last_hid = conv_inputs\n",
    "    for idx in xrange(params.recurrent_length):\n",
    "        scope = 'CONV%d' % idx\n",
    "        last_hid = conv2d(last_hid, 3, [1, 1], \"B\", scope=scope)\n",
    "        print(\"Building %s\" % scope)\n",
    "\n",
    "    # output reccurent layers\n",
    "    for idx in xrange(params.out_recurrent_length):\n",
    "        scope = 'CONV_OUT%d' % idx\n",
    "        last_hid = tf.nn.relu(conv2d(last_hid, params.out_hidden_dims, [1, 1], \"B\", scope=scope))\n",
    "        print(\"Building %s\" % scope)\n",
    "\n",
    "    conv2d_out_logits = conv2d(last_hid, 1, [1, 1], \"B\", scope='conv2d_out_logits')\n",
    "    output = tf.nn.sigmoid(conv2d_out_logits)\n",
    "    return inputs, output, conv2d_out_logits\n",
    "inputs, output, conv2d_out_logits = pixelRNN(height, width, channel, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building pixel_cnn finished!\n"
     ]
    }
   ],
   "source": [
    "loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(conv2d_out_logits, inputs, name='loss'))\n",
    "\n",
    "optimizer = tf.train.RMSPropOptimizer(p.learning_rate)\n",
    "grads_and_vars = optimizer.compute_gradients(loss)\n",
    "\n",
    "new_grads_and_vars = \\\n",
    "    [(tf.clip_by_value(gv[0], -p.grad_clip, p.grad_clip), gv[1]) for gv in grads_and_vars]\n",
    "optim = optimizer.apply_gradients(new_grads_and_vars)\n",
    " \n",
    "# show_all_variables()\n",
    "print(\"Building %s finished!\" % p.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict(sess, images, inputs, output):\n",
    "    return sess.run(output, {inputs: images})\n",
    "\n",
    "def generate(sess, height, width, inputs, output):\n",
    "    samples = np.zeros((100, height, width, 1), dtype='float32')\n",
    "    # TODO add occlusions\n",
    "    for i in xrange(self.height):\n",
    "        for j in xrange(self.width):\n",
    "            for k in xrange(self.channel):\n",
    "                next_sample = binarize(predict(sess, samples, inputs, output))\n",
    "                samples[:, i, j, k] = next_sample[:, i, j, k]\n",
    "\n",
    "    return samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From statistic.py:20 in __init__.: __init__ (from tensorflow.python.training.summary_io) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.FileWriter. The interface and behavior is the same; this is just a rename.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[01-28 21:13:16] From statistic.py:20 in __init__.: __init__ (from tensorflow.python.training.summary_io) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.FileWriter. The interface and behavior is the same; this is just a rename.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From statistic.py:30 in __init__.: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[01-28 21:13:17] From statistic.py:30 in __init__.: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From statistic.py:30 in __init__.: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[01-28 21:13:17] From statistic.py:30 in __init__.: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.\n"
     ]
    },
    {
     "ename": "FailedPreconditionError",
     "evalue": "Attempting to use uninitialized value t/t\n\t [[Node: t/AssignAdd = AssignAdd[T=DT_INT32, _class=[\"loc:@t/t\"], use_locking=false, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](t/t, t/AssignAdd/value)]]\n\nCaused by op u't/AssignAdd', defined at:\n  File \"/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/runpy.py\", line 162, in _run_module_as_main\n    \"__main__\", fname, loader, pkg_name)\n  File \"/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/runpy.py\", line 72, in _run_code\n    exec code in run_globals\n  File \"/Users/philkuz/.virtualenvs/keras/lib/python2.7/site-packages/ipykernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"/Users/philkuz/.virtualenvs/keras/lib/python2.7/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/Users/philkuz/.virtualenvs/keras/lib/python2.7/site-packages/ipykernel/kernelapp.py\", line 474, in start\n    ioloop.IOLoop.instance().start()\n  File \"/Users/philkuz/.virtualenvs/keras/lib/python2.7/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/Users/philkuz/.virtualenvs/keras/lib/python2.7/site-packages/tornado/ioloop.py\", line 887, in start\n    handler_func(fd_obj, events)\n  File \"/Users/philkuz/.virtualenvs/keras/lib/python2.7/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Users/philkuz/.virtualenvs/keras/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/Users/philkuz/.virtualenvs/keras/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/Users/philkuz/.virtualenvs/keras/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/Users/philkuz/.virtualenvs/keras/lib/python2.7/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Users/philkuz/.virtualenvs/keras/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 276, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/Users/philkuz/.virtualenvs/keras/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 228, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/Users/philkuz/.virtualenvs/keras/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 390, in execute_request\n    user_expressions, allow_stdin)\n  File \"/Users/philkuz/.virtualenvs/keras/lib/python2.7/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/Users/philkuz/.virtualenvs/keras/lib/python2.7/site-packages/ipykernel/zmqshell.py\", line 501, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/Users/philkuz/.virtualenvs/keras/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/Users/philkuz/.virtualenvs/keras/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/Users/philkuz/.virtualenvs/keras/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-8-ce40f4ff9787>\", line 4, in <module>\n    stat = Statistic(sess, p.data, model_dir, tf.trainable_variables(), p.test_step)\n  File \"statistic.py\", line 16, in __init__\n    self.t_add_op = self.t_op.assign_add(1)\n  File \"/Users/philkuz/.virtualenvs/keras/lib/python2.7/site-packages/tensorflow/python/ops/variables.py\", line 590, in assign_add\n    return state_ops.assign_add(self._variable, delta, use_locking=use_locking)\n  File \"/Users/philkuz/.virtualenvs/keras/lib/python2.7/site-packages/tensorflow/python/ops/gen_state_ops.py\", line 75, in assign_add\n    use_locking=use_locking, name=name)\n  File \"/Users/philkuz/.virtualenvs/keras/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py\", line 759, in apply_op\n    op_def=op_def)\n  File \"/Users/philkuz/.virtualenvs/keras/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 2240, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/Users/philkuz/.virtualenvs/keras/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 1128, in __init__\n    self._traceback = _extract_stack()\n\nFailedPreconditionError (see above for traceback): Attempting to use uninitialized value t/t\n\t [[Node: t/AssignAdd = AssignAdd[T=DT_INT32, _class=[\"loc:@t/t\"], use_locking=false, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](t/t, t/AssignAdd/value)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFailedPreconditionError\u001b[0m                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-ce40f4ff9787>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mstat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStatistic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mstat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Start training\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/philkuz/projects/mlab/pixelrnn/statistic.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     72\u001b[0m       \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Load FAILED: %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt_add_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/philkuz/.virtualenvs/keras/lib/python2.7/site-packages/tensorflow/python/framework/ops.pyc\u001b[0m in \u001b[0;36meval\u001b[0;34m(self, feed_dict, session)\u001b[0m\n\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \"\"\"\n\u001b[0;32m--> 575\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_eval_using_default_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    576\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/philkuz/.virtualenvs/keras/lib/python2.7/site-packages/tensorflow/python/framework/ops.pyc\u001b[0m in \u001b[0;36m_eval_using_default_session\u001b[0;34m(tensors, feed_dict, graph, session)\u001b[0m\n\u001b[1;32m   3631\u001b[0m                        \u001b[0;34m\"the tensor's graph is different from the session's \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3632\u001b[0m                        \"graph.\")\n\u001b[0;32m-> 3633\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3634\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3635\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/philkuz/.virtualenvs/keras/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    764\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    765\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 766\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    767\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    768\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/philkuz/.virtualenvs/keras/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    962\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    963\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 964\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    965\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    966\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/philkuz/.virtualenvs/keras/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1012\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1014\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1015\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/Users/philkuz/.virtualenvs/keras/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1032\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1033\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1034\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1035\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFailedPreconditionError\u001b[0m: Attempting to use uninitialized value t/t\n\t [[Node: t/AssignAdd = AssignAdd[T=DT_INT32, _class=[\"loc:@t/t\"], use_locking=false, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](t/t, t/AssignAdd/value)]]\n\nCaused by op u't/AssignAdd', defined at:\n  File \"/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/runpy.py\", line 162, in _run_module_as_main\n    \"__main__\", fname, loader, pkg_name)\n  File \"/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/runpy.py\", line 72, in _run_code\n    exec code in run_globals\n  File \"/Users/philkuz/.virtualenvs/keras/lib/python2.7/site-packages/ipykernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"/Users/philkuz/.virtualenvs/keras/lib/python2.7/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/Users/philkuz/.virtualenvs/keras/lib/python2.7/site-packages/ipykernel/kernelapp.py\", line 474, in start\n    ioloop.IOLoop.instance().start()\n  File \"/Users/philkuz/.virtualenvs/keras/lib/python2.7/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/Users/philkuz/.virtualenvs/keras/lib/python2.7/site-packages/tornado/ioloop.py\", line 887, in start\n    handler_func(fd_obj, events)\n  File \"/Users/philkuz/.virtualenvs/keras/lib/python2.7/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Users/philkuz/.virtualenvs/keras/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/Users/philkuz/.virtualenvs/keras/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/Users/philkuz/.virtualenvs/keras/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/Users/philkuz/.virtualenvs/keras/lib/python2.7/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Users/philkuz/.virtualenvs/keras/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 276, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/Users/philkuz/.virtualenvs/keras/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 228, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/Users/philkuz/.virtualenvs/keras/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 390, in execute_request\n    user_expressions, allow_stdin)\n  File \"/Users/philkuz/.virtualenvs/keras/lib/python2.7/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/Users/philkuz/.virtualenvs/keras/lib/python2.7/site-packages/ipykernel/zmqshell.py\", line 501, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/Users/philkuz/.virtualenvs/keras/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/Users/philkuz/.virtualenvs/keras/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/Users/philkuz/.virtualenvs/keras/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-8-ce40f4ff9787>\", line 4, in <module>\n    stat = Statistic(sess, p.data, model_dir, tf.trainable_variables(), p.test_step)\n  File \"statistic.py\", line 16, in __init__\n    self.t_add_op = self.t_op.assign_add(1)\n  File \"/Users/philkuz/.virtualenvs/keras/lib/python2.7/site-packages/tensorflow/python/ops/variables.py\", line 590, in assign_add\n    return state_ops.assign_add(self._variable, delta, use_locking=use_locking)\n  File \"/Users/philkuz/.virtualenvs/keras/lib/python2.7/site-packages/tensorflow/python/ops/gen_state_ops.py\", line 75, in assign_add\n    use_locking=use_locking, name=name)\n  File \"/Users/philkuz/.virtualenvs/keras/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py\", line 759, in apply_op\n    op_def=op_def)\n  File \"/Users/philkuz/.virtualenvs/keras/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 2240, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/Users/philkuz/.virtualenvs/keras/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 1128, in __init__\n    self._traceback = _extract_stack()\n\nFailedPreconditionError (see above for traceback): Attempting to use uninitialized value t/t\n\t [[Node: t/AssignAdd = AssignAdd[T=DT_INT32, _class=[\"loc:@t/t\"], use_locking=false, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](t/t, t/AssignAdd/value)]]\n"
     ]
    }
   ],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    stat = Statistic(sess, p.data, model_dir, tf.trainable_variables(), p.test_step)\n",
    "    stat.load_model()\n",
    "    print(\"Start training\")\n",
    "    \n",
    "    initial_step = stat.get_t() if stat else 0\n",
    "    iterator = trange(p.max_epoch, ncols=70, initial=initial_step)\n",
    "\n",
    "    for epoch in iterator:\n",
    "        # 1. train\n",
    "        total_train_costs = []\n",
    "        for idx in xrange(train_step_per_epoch):\n",
    "            images = binarize(next_train_batch(p.batch_size)) \\\n",
    "                .reshape([p.batch_size, height, width, channel])\n",
    "\n",
    "            _, cost = sess.run([optim, loss], feed_dict={ inputs: images })\n",
    "            total_train_costs.append(cost)\n",
    "\n",
    "        # 2. test\n",
    "        total_test_costs = []\n",
    "        for idx in xrange(test_step_per_epoch):\n",
    "            images = binarize(next_test_batch(p.batch_size)) \\\n",
    "                .reshape([p.batch_size, height, width, channel])\n",
    "\n",
    "            cost = sess.run(loss, feed_dict={ inputs : images })\n",
    "            total_test_costs.append(cost)\n",
    "\n",
    "        avg_train_cost, avg_test_cost = np.mean(total_train_costs), np.mean(total_test_costs)\n",
    "\n",
    "        stat.on_step(avg_train_cost, avg_test_cost)\n",
    "\n",
    "        # 3. generate samples\n",
    "        samples = generate(ses, height, width, inputs, output)\n",
    "        save_images(samples, height, width, 10, 10, \n",
    "            directory=SAMPLE_DIR, prefix=\"epoch_%s\" % epoch)\n",
    "\n",
    "        iterator.set_description(\"train l: %.3f, test l: %.3f\" % (avg_train_cost, avg_test_cost))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    samples = generate(sess, height, width, inputs, output)\n",
    "    save_images(samples, height, width, 10, 10, directory=SAMPLE_DIR)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "from tqdm import trange\n",
    "import tensorflow as tf\n",
    "\n",
    "from utils import *\n",
    "from ops import *\n",
    "from statistic import Statistic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set the parameters of the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hyperparams = {# network\n",
    "    \"model\" : \"pixel_cnn\", # name of model [pixel_rnn, pixel_cnn]\n",
    "    \"batch_size\" : 100, # size of a batch\n",
    "    \"hidden_dims\" : 16, # dimesion of hidden states of LSTM or Conv layers\n",
    "    \"recurrent_length\" : 7, # the length of LSTM or Conv layers\n",
    "    \"out_hidden_dims\" : 32, # dimesion of hidden states of output Conv layers\n",
    "    \"out_recurrent_length\" : 2, # the length of output Conv layers\n",
    "    \"use_residual\" : False, # whether to use residual connections or not\n",
    "    \"use_dynamic_rnn\" : False, # whether to use dynamic_rnn or not\n",
    "\n",
    "    # training\n",
    "    \"max_epoch\" : 100000, # # of step in an epoch\n",
    "    \"test_step\" : 100, # # of step to test a model\n",
    "    \"save_step\" : 1000, # # of step to save a model\n",
    "    \"learning_rate\" : 1e-3, # learning rate\n",
    "    \"grad_clip\" : 1, # value of gradient to be used for clipping\n",
    "    \"use_gpu\" : True, # whether to use gpu for training\n",
    "\n",
    "    # data\n",
    "    \"data\" : \"mnist\", # name of dataset \n",
    "    \"data_dir\" : \"MNIST-data\", # name of data directory\n",
    "    \"sample_dir\" : \"samples\", # name of sample directory\n",
    "\n",
    "    # Debug\n",
    "    \"is_train\" : True, # training or testing\n",
    "    \"display\" : False, # whether to display the training results or not\n",
    "    \"random_seed\" :  123 # random seed for python\n",
    "}\n",
    "p = dotdict(hyperparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if \"random_seed\" in p:\n",
    "    tf.set_random_seed(p.random_seed)\n",
    "    np.random.seed(p.random_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TODO add hyperparams to model saving\n",
    "model_dir = setup_model_saving(p.model, p.data, hyperparams)\n",
    "DATA_DIR = p.data_dir\n",
    "SAMPLE_DIR = os.path.join(model_dir, p.sample_dir)\n",
    "\n",
    "check_and_create_dir(DATA_DIR)\n",
    "check_and_create_dir(SAMPLE_DIR)\n",
    "\n",
    "# prepare dataset\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(DATA_DIR, one_hot=True)\n",
    "\n",
    "next_train_batch = lambda x: mnist.train.next_batch(x)[0]\n",
    "next_test_batch = lambda x: mnist.test.next_batch(x)[0]\n",
    "\n",
    "height, width, channel = 28, 28, 1\n",
    "\n",
    "train_step_per_epoch = mnist.train.num_examples / p.batch_size\n",
    "test_step_per_epoch = mnist.test.num_examples / p.batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def pixelRNN(height, width, channel, params):\n",
    "    \"\"\"\n",
    "    Args\n",
    "    height, width, channel - the dimensions of the input\n",
    "    params -- the hyperparameters of the network\n",
    "    \"\"\"\n",
    "    input_shape = [None, height, width, channel] if params.use_gpu else [None, channel, height, width]\n",
    "    inputs = tf.placeholder(tf.float32, input_shape)\n",
    "    \n",
    "    # TODO remove scoping\n",
    "    # input of main reccurent layers\n",
    "    scope = \"conv_inputs\"\n",
    "    conv_inputs = conv2d(inputs, params.hidden_dims, [7, 7], \"A\", scope=scope)\n",
    "    \n",
    "    # main reccurent layers\n",
    "    last_hid = conv_inputs\n",
    "    for idx in xrange(params.recurrent_length):\n",
    "        scope = 'CONV%d' % idx\n",
    "        last_hid = conv2d(last_hid, 3, [1, 1], \"B\", scope=scope)\n",
    "        print(\"Building %s\" % scope)\n",
    "\n",
    "    # output reccurent layers\n",
    "    for idx in xrange(params.out_recurrent_length):\n",
    "        scope = 'CONV_OUT%d' % idx\n",
    "        last_hid = tf.nn.relu(conv2d(last_hid, params.out_hidden_dims, [1, 1], \"B\", scope=scope))\n",
    "        print(\"Building %s\" % scope)\n",
    "\n",
    "    conv2d_out_logits = conv2d(last_hid, 1, [1, 1], \"B\", scope='conv2d_out_logits')\n",
    "    output = tf.nn.sigmoid(conv2d_out_logits)\n",
    "    return inputs, output, conv2d_out_logits\n",
    "inputs, output, conv2d_out_logits = pixelRNN(height, width, channel, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(conv2d_out_logits, inputs, name='loss'))\n",
    "\n",
    "optimizer = tf.train.RMSPropOptimizer(p.learning_rate)\n",
    "grads_and_vars = optimizer.compute_gradients(loss)\n",
    "\n",
    "new_grads_and_vars = \\\n",
    "    [(tf.clip_by_value(gv[0], -p.grad_clip, p.grad_clip), gv[1]) for gv in grads_and_vars]\n",
    "optim = optimizer.apply_gradients(new_grads_and_vars)\n",
    " \n",
    "# show_all_variables()\n",
    "print(\"Building %s finished!\" % p.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict(sess, images, inputs, output):\n",
    "    return sess.run(output, {inputs: images})\n",
    "\n",
    "def generate(sess, height, width, inputs, output):\n",
    "    samples = np.zeros((100, height, width, 1), dtype='float32')\n",
    "\n",
    "    for i in xrange(height):\n",
    "        for j in xrange(width):\n",
    "            for k in xrange(channel):\n",
    "                next_sample = binarize(predict(sess, samples, inputs, output))\n",
    "                samples[:, i, j, k] = next_sample[:, i, j, k]\n",
    "\n",
    "    return samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "with tf.Session() as sess:\n",
    "\n",
    "    stat = Statistic(sess, p.data, model_dir, tf.trainable_variables(), p.test_step)\n",
    "    stat.load_model()\n",
    "    init = tf.initialize_all_variables()\n",
    "\n",
    "    sess.run(init)\n",
    "    stat.start()\n",
    "    print(\"Start training\")\n",
    "    \n",
    "    initial_step = stat.get_t() if stat else 0\n",
    "    iterator = trange(p.max_epoch, ncols=70, initial=initial_step)\n",
    "\n",
    "    for epoch in iterator:\n",
    "        print('Start epoch')\n",
    "        # 1. train\n",
    "        total_train_costs = []\n",
    "        for idx in xrange(train_step_per_epoch):\n",
    "            images = binarize(next_train_batch(p.batch_size)) \\\n",
    "                .reshape([p.batch_size, height, width, channel])\n",
    "\n",
    "            _, cost = sess.run([optim, loss], feed_dict={ inputs: images })\n",
    "            total_train_costs.append(cost)\n",
    "        print('Start testing')\n",
    "        # 2. test\n",
    "        total_test_costs = []\n",
    "        for idx in xrange(test_step_per_epoch):\n",
    "            images = binarize(next_test_batch(p.batch_size)) \\\n",
    "                .reshape([p.batch_size, height, width, channel])\n",
    "\n",
    "            cost = sess.run(loss, feed_dict={ inputs : images })\n",
    "            total_test_costs.append(cost)\n",
    "\n",
    "        avg_train_cost, avg_test_cost = np.mean(total_train_costs), np.mean(total_test_costs)\n",
    "\n",
    "        stat.on_step(avg_train_cost, avg_test_cost)\n",
    "        print('Start generation')\n",
    "        # 3. generate samples\n",
    "        samples = generate(sess, height, width, inputs, output)\n",
    "        save_images(samples, height, width, 10, 10, \n",
    "            directory=SAMPLE_DIR, prefix=\"epoch_%s\" % epoch)\n",
    "\n",
    "        iterator.set_description(\"train l: %.3f, test l: %.3f\" % (avg_train_cost, avg_test_cost))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    samples = generate(sess, height, width, inputs, output)\n",
    "    save_images(samples, height, width, 10, 10, directory=SAMPLE_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "fname = save_images(samples, height, widht, 10, 10, directory=SAMPLE_DIR)\n",
    "Image(filename=fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
